import path from "path";
import { fileURLToPath } from "url";
import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import OpenAI from "openai";
// ===============================
// Daily AI limit (MVP â€“ in memory)
// ===============================
const DAILY_LIMIT = Number(process.env.DAILY_AI_CALL_LIMIT || 200);

let currentDay = new Date().toISOString().slice(0, 10); // YYYY-MM-DD
let aiCallsByHotel = new Map();

function resetIfNewDay() {
  const today = new Date().toISOString().slice(0, 10);
  if (today !== currentDay) {
    currentDay = today;
    aiCallsByHotel = new Map();
  }
}

function canCallAI(hotelId) {
  resetIfNewDay();
  const key = hotelId || "unknown";
  const used = aiCallsByHotel.get(key) || 0;
  return used < DAILY_LIMIT;
}

function incrementAI(hotelId) {
  resetIfNewDay();
  const key = hotelId || "unknown";
  const used = aiCallsByHotel.get(key) || 0;
  aiCallsByHotel.set(key, used + 1);
}

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3000;

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ---- MVP knobs (env optional) ----
const MODEL = process.env.OPENAI_MODEL || "gpt-4o-mini";
const MAX_OUTPUT_TOKENS = Number(process.env.OPENAI_MAX_OUTPUT_TOKENS || 220);
const TEMPERATURE = Number(process.env.OPENAI_TEMPERATURE || 0.2);
const RATE_LIMIT_PER_MINUTE = Number(process.env.RATE_LIMIT_PER_MINUTE || 12);
const MAX_MESSAGE_CHARS = Number(process.env.MAX_MESSAGE_CHARS || 600);

// ---- OpenAI client (reads OPENAI_API_KEY from env) ----
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ---- Middleware ----
app.use(cors());
app.use(express.json({ limit: "100kb" }));

// ---- Serve static files ----
app.use(express.static(path.join(__dirname, "public")));

// ---- Demo page ----
app.get("/demo", (req, res) => {
  res.sendFile(path.join(__dirname, "demo", "demo-hotel.html"));
});

/**
 * Health check
 */
app.get("/", (req, res) => {
  res.send("Hotel AI SaaS backend is running ðŸš€");
});

app.get("/api/health", (req, res) => {
  res.json({
    ok: true,
    hasOpenAIKey: Boolean(process.env.OPENAI_API_KEY),
    model: MODEL,
  });
});

// ---- Simple in-memory rate limit (per hotel_id + session_id) ----
const buckets = new Map(); // key -> { count, windowStartMs }
function hitRateLimit(key) {
  const now = Date.now();
  const windowMs = 60_000;

  const entry = buckets.get(key);
  if (!entry || now - entry.windowStartMs > windowMs) {
    buckets.set(key, { count: 1, windowStartMs: now });
    return false;
  }
  entry.count += 1;
  return entry.count > RATE_LIMIT_PER_MINUTE;
}

// ---- FAQ-first (MVP hardcoded) ----
const FAQ = [
  {
    match: [/check[- ]?in/i, /Ï„ÏƒÎµÎº ?Î¹Î½/i, /Î¬Ï†Î¹Î¾Î·/i],
    answer:
      "Î¤Î¿ check-in ÎµÎ¯Î½Î±Î¹ Î±Ï€ÏŒ 15:00. Î‘Î½ Ï†Ï„Î¬ÏƒÎµÏ„Îµ Î½Ï‰ÏÎ¯Ï„ÎµÏÎ±, Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± ÎºÏÎ±Ï„Î®ÏƒÎ¿Ï…Î¼Îµ Ï„Î¹Ï‚ Î±Ï€Î¿ÏƒÎºÎµÏ…Î­Ï‚ ÏƒÎ±Ï‚ Î¼Î­Ï‡ÏÎ¹ Î½Î± ÎµÎ¯Î½Î±Î¹ Î­Ï„Î¿Î¹Î¼Î¿ Ï„Î¿ Î´Ï‰Î¼Î¬Ï„Î¹Î¿.",
  },
  {
    match: [/check[- ]?out/i, /Ï„ÏƒÎµÎº ?Î¬Î¿Ï…Ï„/i, /Î±Î½Î±Ï‡ÏŽÏÎ·ÏƒÎ·/i],
    answer:
      "Î¤Î¿ check-out ÎµÎ¯Î½Î±Î¹ Î­Ï‰Ï‚ 11:00. Î‘Î½ Î¸Î­Î»ÎµÏ„Îµ late check-out, Ï€ÎµÎ¯Ï„Îµ Î¼Î¿Ï… Ï€ÎµÏÎ¯Ï€Î¿Ï… Ï„Î¹ ÏŽÏÎ± ÎºÎ±Î¹ Î¸Î± ÏƒÎ±Ï‚ ÎµÎ½Î·Î¼ÎµÏÏŽÏƒÏ‰ Î³Î¹Î± Î´Î¹Î±Î¸ÎµÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î±/Ï€Î¹Î¸Î±Î½Î® Ï‡ÏÎ­Ï‰ÏƒÎ·.",
  },
  {
    match: [/parking/i, /Ï€Î±ÏÎº/i, /ÏƒÏ„Î¬Î¸Î¼ÎµÏ…ÏƒÎ·/i],
    answer:
      "Î“Î¹Î± parking: Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿Ï‚ Ï‡ÏŽÏÎ¿Ï‚ ÏƒÏ„Î¬Î¸Î¼ÎµÏ…ÏƒÎ·Ï‚ (Î±Î½Î¬Î»Î¿Î³Î± Î¼Îµ Î´Î¹Î±Î¸ÎµÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î±). Î˜Î­Î»ÎµÏ„Îµ Î½Î± Î¼Î¿Ï… Ï€ÎµÎ¯Ï„Îµ Î±Î½ Î­ÏÏ‡ÎµÏƒÏ„Îµ Î¼Îµ Î±Ï…Ï„Î¿ÎºÎ¯Î½Î·Ï„Î¿ ÎºÎ±Î¹ Ï€ÎµÏÎ¯Ï€Î¿Ï… Ï„Î¹ ÏŽÏÎ±;",
  },
  {
    match: [/breakfast/i, /Ï€ÏÏ‰Î¹Î½/i],
    answer:
      "Î¤Î¿ Ï€ÏÏ‰Î¹Î½ÏŒ ÏƒÎµÏÎ²Î¯ÏÎµÏ„Î±Î¹ 07:30â€“10:30. Î‘Î½ Î­Ï‡ÎµÏ„Îµ Î±Î»Î»ÎµÏÎ³Î¯ÎµÏ‚ Î® ÎµÎ¹Î´Î¹ÎºÎ® Î´Î¹Î±Ï„ÏÎ¿Ï†Î®, Ï€ÎµÎ¯Ï„Îµ Î¼Î¿Ï… Ï„Î¹ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏƒÏ„Îµ.",
  },
];

function faqFirst(text) {
  const msg = (text || "").trim();
  if (!msg) return null;

  for (const item of FAQ) {
    if (item.match.some((re) => re.test(msg))) return item.answer;
  }
  return null;
}

/**
 * MVP chat endpoint (FAQ-first + OpenAI fallback)
 * Body: { hotel_id, session_id, message }
 */
app.post("/api/chat", async (req, res) => {
  try {
    const { hotel_id, session_id, message } = req.body || {};

    if (!hotel_id || typeof message !== "string") {
      return res.status(400).json({ error: "Missing hotel_id or message" });
    }

    const msg = message.trim();
    if (!msg) return res.status(400).json({ error: "Empty message" });

    if (msg.length > MAX_MESSAGE_CHARS) {
      return res
        .status(413)
        .json({ error: `Message too long (max ${MAX_MESSAGE_CHARS} chars)` });
    }

    const sid = session_id || "no-session";
    const key = `${hotel_id}:${sid}`;

    if (hitRateLimit(key)) {
      return res.status(429).json({ error: "Too many messages. Please slow down." });
    }

    // 1) FAQ-first (0 cost)
    const faqReply = faqFirst(msg);
    if (faqReply) {
      return res.json({ reply: faqReply, source: "faq" });
    }

    // 2) OpenAI fallback
    if (!process.env.OPENAI_API_KEY) {
      return res.json({
        reply: `(${hotel_id}) Î›Î¬Î²Î±Î¼Îµ Ï„Î¿ Î¼Î®Î½Ï…Î¼Î±: "${msg}"`,
        source: "dummy",
      });
    }

    const instructions =
      "You are a friendly, concise hotel receptionist. " +
      "Answer in Greek unless the user writes in English. " +
      "If the guest asks for something you cannot know (prices, availability, booking confirmation), ask ONE short follow-up question. " +
      "Keep responses short (1-4 sentences).";

    const input =
      `Hotel ID: ${hotel_id}\n` +
      `Session ID: ${sid}\n` +
      `Guest message: ${msg}\n\n` +
      "Reply as the hotel's receptionist.";

    // Daily AI limit guard (counts only OpenAI fallback)
if (!canCallAI(hotel_id)) {
  return res.status(429).json({
    ok: false,
    source: "limit",
    reply: `ÎˆÏ‡Î¿Ï…Î¼Îµ Ï†Ï„Î¬ÏƒÎµÎ¹ Ï„Î¿ Î·Î¼ÎµÏÎ®ÏƒÎ¹Î¿ ÏŒÏÎ¹Î¿ AI Î³Î¹Î± ÏƒÎ®Î¼ÎµÏÎ±. Î¡ÏŽÏ„Î± ÎºÎ¬Ï„Î¹ Î±Ï€ÏŒ Ï„Î± FAQ (check-in, check-out, parking, breakfast) Î® Î´Î¿ÎºÎ¯Î¼Î±ÏƒÎµ Î¾Î±Î½Î¬ Î±ÏÏÎ¹Î¿ ðŸ™‚`,
  });
}
const response = await openai.responses.create({
      model: MODEL,
      instructions,
      input,
      max_output_tokens: MAX_OUTPUT_TOKENS,
      temperature: TEMPERATURE,
    });
incrementAI(hotel_id);

    return res.json({
      reply:
        response.output_text ||
        "Î£Ï…Î³Î³Î½ÏŽÎ¼Î·, Î´ÎµÎ½ ÎºÎ±Ï„Î¬Ï†ÎµÏÎ± Î½Î± Î±Ï€Î±Î½Ï„Î®ÏƒÏ‰. Î˜Î­Î»ÎµÎ¹Ï‚ Î½Î± Ï„Î¿ Ï€ÎµÎ¹Ï‚ Î»Î¯Î³Î¿ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬;",
      source: "openai",
    });
  } catch (err) {
    console.error("Chat error:", err);
    return res.status(500).json({
      error: "Server error",
      reply: "Î¥Ï€Î®ÏÎ¾Îµ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½ÏŒ Ï€ÏÏŒÎ²Î»Î·Î¼Î±. Î”Î¿ÎºÎ¯Î¼Î±ÏƒÎµ Î¾Î±Î½Î¬ ÏƒÎµ Î»Î¯Î³Î¿.",
    });
  }
});

app.listen(PORT, () => {
  console.log(`âœ… Server running on port ${PORT}`);
});
